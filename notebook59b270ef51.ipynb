{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-22T01:37:50.820323Z","iopub.status.busy":"2024-03-22T01:37:50.819904Z","iopub.status.idle":"2024-03-22T01:37:52.183931Z","shell.execute_reply":"2024-03-22T01:37:52.182754Z","shell.execute_reply.started":"2024-03-22T01:37:50.820293Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/midddd2/mid.csv\n"]}],"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:37:52.187357Z","iopub.status.busy":"2024-03-22T01:37:52.186100Z","iopub.status.idle":"2024-03-22T01:38:39.909435Z","shell.execute_reply":"2024-03-22T01:38:39.907882Z","shell.execute_reply.started":"2024-03-22T01:37:52.187314Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyiwn in /opt/conda/lib/python3.10/site-packages (0.0.5)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from pyiwn) (2.2.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pyiwn) (2.31.0)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas->pyiwn) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->pyiwn) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->pyiwn) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->pyiwn) (2023.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pyiwn) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pyiwn) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pyiwn) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pyiwn) (2024.2.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->pyiwn) (1.16.0)\n","Requirement already satisfied: googletrans==4.0.0-rc1 in /opt/conda/lib/python3.10/site-packages (4.0.0rc1)\n","Requirement already satisfied: httpx==0.13.3 in /opt/conda/lib/python3.10/site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.2)\n","Requirement already satisfied: hstspreload in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.3.1)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n","Requirement already satisfied: chardet==3.* in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n","Requirement already satisfied: idna==2.* in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n","Requirement already satisfied: rfc3986<2,>=1.3 in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n","Requirement already satisfied: httpcore==0.9.* in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n","Requirement already satisfied: h11<0.10,>=0.8 in /opt/conda/lib/python3.10/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n","Requirement already satisfied: h2==3.* in /opt/conda/lib/python3.10/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n","Requirement already satisfied: hyperframe<6,>=5.2.0 in /opt/conda/lib/python3.10/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n","Requirement already satisfied: hpack<4,>=3.0 in /opt/conda/lib/python3.10/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.0)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.2.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"]}],"source":["!pip install pyiwn\n","!pip install googletrans==4.0.0-rc1\n","!pip install datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:38:39.912916Z","iopub.status.busy":"2024-03-22T01:38:39.912525Z","iopub.status.idle":"2024-03-22T01:38:40.184647Z","shell.execute_reply":"2024-03-22T01:38:40.183491Z","shell.execute_reply.started":"2024-03-22T01:38:39.912884Z"},"trusted":true},"outputs":[],"source":["from enum import Enum, unique\n","import re\n","import logging\n","import glob\n","import ntpath\n","import os\n","\n","import pandas as pd\n","\n","import pyiwn.constants as constants\n","\n","\n","logging.basicConfig(format='[%(filename)s:%(lineno)d] %(message)s',\n","    datefmt='%Y-%m-%d:%H:%M:%S',\n","    level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","\n","\n","@unique\n","class Language(Enum):\n","    ASSAMESE = 'assamese'\n","    BENGALI = 'bengali'\n","    BODO = 'bodo'\n","    GUJARATI = 'gujarati'\n","    HINDI = 'hindi'\n","    KANNADA = 'kannada'\n","    KASHMIRI = 'kashmiri'\n","    KONKANI = 'konkani'\n","    MALAYALAM = 'malayalam'\n","    MARATHI = 'marathi'\n","    MEITEI = 'meitei'\n","    NEPALI = 'nepali'\n","    ORIYA = 'oriya'\n","    PUNJABI = 'punjabi'\n","    SANSKRIT = 'sanskrit'\n","    TAMIL = 'tamil'\n","    TELUGU = 'telugu'\n","    URDU = 'urdu'\n","\n","\n","class IndoWordNet:\n","    def __init__(self, lang=Language.HINDI):\n","        logger.info(f'Loading {lang.value} language synsets...')\n","        self._synset_idx_map = {}\n","        self._synset_df = self._load_synset_file(lang.value)\n","        self._synset_relations_dict = self._load_synset_relations()\n","\n","    def _load_synset_file(self, lang):\n","        filename = os.path.join(*[constants.IWN_DATA_PATH, 'synsets', 'all.{}'.format(lang)])\n","        f = open(filename, encoding='utf-8')\n","        synsets = list(map(lambda line: self._load_synset(line), f.readlines()))\n","        synset_df = pd.DataFrame(synsets, columns=['synset_id', 'synsets', 'pos'])\n","        synset_df = synset_df.dropna()\n","        synset_df = synset_df.set_index('synset_id')\n","        return synset_df\n","\n","    def _load_synset_relations(self):\n","        relations_dict = {}\n","        for file_path, relation_name in self._relation_list():\n","            relations_dict[relation_name] = []\n","            d = {}\n","            for line in open(file_path):\n","                line_parts = line.split('\\t')\n","                synset_id, synset_ids = line_parts\n","                synset_id = int(synset_id)\n","                synset_ids = list(map(int, synset_ids.split(',')))\n","                synset_ids = list(filter(lambda x: True if x in self._synset_df.index else False, synset_ids))\n","                if synset_id in d:\n","                    d[synset_id].extend(synset_ids)\n","                else:\n","                    if synset_ids:\n","                        d[synset_id] = synset_ids\n","            relations_dict[relation_name] = d\n","        return relations_dict\n","\n","    def _relation_list(self, type='synset_relations'):\n","        relations = []\n","        path_parts = '{},{},*'.format(constants.IWN_DATA_PATH, type).split(',')\n","        for file_path in glob.glob(os.path.join(*path_parts)):\n","            file_name = ntpath.basename(file_path)\n","            file_name_parts = file_name.split('.')\n","            if len(file_name_parts) != 2:\n","                continue\n","            relation_name, pos_tag = file_name_parts\n","            relations.append((file_path, relation_name))\n","        return relations\n","\n","    def _update_synset_idx_map(self, synset):\n","        synset_id = synset.synset_id()\n","        for word in synset.lemma_names():\n","            if word in self._synset_idx_map:\n","                self._synset_idx_map[word].append(synset_id)\n","            else:\n","                self._synset_idx_map[word] = [synset_id]\n","        return True\n","\n","    def _load_synset(self, synset_string):\n","        if 'null' in synset_string:\n","            return None, None, None\n","\n","        synset_string = synset_string.replace('\\n', '').strip()\n","        synset_pattern = '([0-9]+)\\t(.+)\\t(.+)\\t([a-zA-Z]+)'\n","        try:\n","            matches = re.findall(synset_pattern, synset_string)\n","            synset_id, synset_words, gloss_examples, pos = matches[0]\n","        except Exception as e:\n","            return None, None, None\n","\n","        synset_id = int(synset_id)\n","        synset_words = list(filter(lambda x: False if x == '' else True, synset_words.split(',')))\n","        if not synset_words:\n","            return None, None, None\n","        head_word = synset_words[0]\n","        if gloss_examples != '':\n","            if ':\"' in gloss_examples:\n","                ge_list = gloss_examples.split(':')\n","                gloss = ge_list[0]\n","                if len(ge_list) > 1:\n","                    examples = ''.join(ge_list[1:])\n","                    examples = re.sub('[\"]', '', examples)\n","                    examples = examples.split('  /  ')\n","                else:\n","                    examples = []\n","            else:\n","                gloss = gloss_examples\n","                examples = []\n","        else:\n","            return None, None, None\n","        synset = Synset(synset_id, head_word, synset_words, pos, gloss, examples)\n","\n","        self._update_synset_idx_map(synset)\n","\n","        return synset_id, synset, pos\n","\n","    def all_synsets(self, pos=None):\n","        if pos is None:\n","            result = self._synset_df\n","        else:\n","            mask = (self._synset_df.pos == pos.value)\n","            result = self._synset_df[mask]\n","        return list(result['synsets'].values)\n","\n","    def synsets(self, word, pos=None):\n","        synset_id_list = self._synset_idx_map[word]\n","\n","        synsets = []\n","        if pos is not None:\n","            for synset_id in synset_id_list:\n","                synset = self._synset_df.loc[[synset_id]]['synsets'].values[0]\n","                if synset.pos() == pos:\n","                    synsets.append(synset)\n","        else:\n","            for synset_id in synset_id_list:\n","                synset = self._synset_df.loc[[synset_id]]['synsets'].values[0]\n","                synsets.append(synset)\n","\n","        return synsets\n","\n","    def all_words(self, pos=None):\n","        if pos is None:\n","            return list(self._synset_idx_map.keys())\n","\n","        words = set()\n","        mask = (self._synset_df.pos == pos.value)\n","        for synset in self._synset_df[mask]['synsets'].values:\n","            for word in synset.lemma_names():\n","                words.add(word)\n","        words = list(words)\n","        return words\n","\n","    def synset_relation(self, synset, relation):\n","        return list(self._synset_df[self._synset_df.index.isin(self._synset_relations_dict[relation.value].get(synset.synset_id(), []))]['synsets'])\n","\n","\n","class Synset:\n","    def __init__(self, synset_id, head_word, lemma_names, pos, gloss, examples):\n","        self._synset_id = synset_id\n","        self._head_word = head_word\n","        self._lemma_names = lemma_names\n","        self._pos = pos\n","        self._gloss = gloss\n","        self._examples = examples\n","\n","    def __repr__(self):\n","        return 'Synset(\\'{}.{}.{}\\')'.format(self._head_word, self._pos, self._synset_id)\n","\n","    def synset_id(self):\n","        return self._synset_id\n","\n","    def head_word(self):\n","        return self._head_word\n","\n","    def lemma_names(self):\n","        return self._lemma_names\n","\n","    def lemmas(self):\n","        return [Lemma(self, lemma) for lemma in self._lemma_names]\n","\n","    def pos(self):\n","        return self._pos  \n","\n","    def gloss(self):\n","        return self._gloss\n","\n","    def examples(self):\n","        return self._examples\n","\n","    def ontology_nodes(self):\n","        raise NotImplementedError(\"This method will be implemented soon.\")\n","\n","\n","class Lemma:\n","    def __init__(self, synset, name):\n","        self._synset = synset\n","        self._name = name\n","\n","    def __repr__(self):\n","        return 'Lemma(\\'{}.{}.{}.{}\\')'.format(self._synset.head_word(), self._synset.pos(), self._synset.synset_id(), self._name)\n","\n","    def name(self):\n","        return self._name\n","\n","    def synset(self):\n","        return self._synset\n","\n","    def gradation(self):\n","        raise NotImplementedError(\"This method will be implemented soon.\")\n","\n","    def antonym(self):\n","        raise NotImplementedError(\"This method will be implemented soon.\")\n","\n","\n","@unique\n","class PosTag(Enum):\n","    NOUN = 'noun'\n","    VERB = 'verb'\n","    ADVERB = 'adverb'\n","    ADJECTIVE = 'adjective'\n","\n","\n","class IndoWordNetError(Exception):\n","    \"\"\" An exception class for IndoWordNet-related errors. \"\"\"\n","\n","\n","@unique\n","class SynsetRelations(Enum):\n","    MERO_MEMBER_COLLECTION = 'mero_member_collection'\n","    ABILITY_VERB = 'ability_verb'\n","    CAUSATIVE = 'causative'\n","    CAPABILITY_VERB = 'capability_verb'\n","    MERO_COMPONENT_OBJECT = 'mero_component_object'\n","    HOLO_PORTION_MASS = 'holo_portion_mass'\n","    FUNCTION_VERB = 'function_verb'\n","    HOLO_COMPONENT_OBJECT = 'holo_component_object'\n","    HYPERNYMY = 'hypernymy'\n","    ENTAILMENT = 'entailment'\n","    ALSO_SEE = 'also_see'\n","    MERO_FEATURE_ACTIVITY = 'mero_feature_activity'\n","    HOLO_PLACE_AREA = 'holo_place_area'\n","    MODIFIES_VERB = 'modifies_verb'\n","    ATTRIBUTES = 'attributes'\n","    MERO_PORTION_MASS = 'mero_portion_mass'\n","    MODIFIES_NOUN = 'modifies_noun'\n","    HOLO_FEATURE_ACTIVITY = 'holo_feature_activity'\n","    MERO_STUFF_OBJECT = 'mero_stuff_object'\n","    TROPONYMY = 'troponymy'\n","    MERO_PLACE_AREA = 'mero_place_area'\n","    HOLO_MEMBER_COLLECTION = 'holo_member_collection'\n","    HYPONYMY = 'hyponymy'\n","    SIMILAR = 'similar'\n","    MERO_POSITION_AREA = 'mero_position_area'\n","    HOLO_POSITION_AREA = 'holo_position_area'\n","    HOLO_STUFF_OBJECT = 'holo_stuff_object'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:38:40.188425Z","iopub.status.busy":"2024-03-22T01:38:40.187898Z","iopub.status.idle":"2024-03-22T01:38:55.325718Z","shell.execute_reply":"2024-03-22T01:38:55.324229Z","shell.execute_reply.started":"2024-03-22T01:38:40.188385Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting indic-nlp-library"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -rotobuf (c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ywin32 (c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ywin32 (c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages)\n","\n","[notice] A new release of pip is available: 23.1.2 -> 24.0\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["\n","  Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n","                                              0.0/40.3 kB ? eta -:--:--\n","     -------------------------------------- 40.3/40.3 kB 968.4 kB/s eta 0:00:00\n","Collecting sphinx-argparse (from indic-nlp-library)\n","  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n","Collecting sphinx-rtd-theme (from indic-nlp-library)\n","  Downloading sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl (2.8 MB)\n","                                              0.0/2.8 MB ? eta -:--:--\n","     --                                       0.2/2.8 MB 5.0 MB/s eta 0:00:01\n","     -------                                  0.5/2.8 MB 6.3 MB/s eta 0:00:01\n","     -----------                              0.8/2.8 MB 6.6 MB/s eta 0:00:01\n","     ------------------                       1.3/2.8 MB 7.4 MB/s eta 0:00:01\n","     ---------------------                    1.5/2.8 MB 6.9 MB/s eta 0:00:01\n","     ---------------------------              1.9/2.8 MB 7.3 MB/s eta 0:00:01\n","     --------------------------------         2.3/2.8 MB 7.3 MB/s eta 0:00:01\n","     ------------------------------------     2.6/2.8 MB 7.2 MB/s eta 0:00:01\n","     ---------------------------------------- 2.8/2.8 MB 6.9 MB/s eta 0:00:00\n","Collecting morfessor (from indic-nlp-library)\n","  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n","Requirement already satisfied: pandas in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from indic-nlp-library) (2.1.1)\n","Requirement already satisfied: numpy in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from indic-nlp-library) (1.23.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from pandas->indic-nlp-library) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from pandas->indic-nlp-library) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from pandas->indic-nlp-library) (2023.3)\n","Collecting sphinx>=1.2.0 (from sphinx-argparse->indic-nlp-library)\n","  Downloading sphinx-7.2.6-py3-none-any.whl (3.2 MB)\n","                                              0.0/3.2 MB ? eta -:--:--\n","     ------                                   0.5/3.2 MB 16.2 MB/s eta 0:00:01\n","     ---------                                0.8/3.2 MB 12.4 MB/s eta 0:00:01\n","     -------------                            1.1/3.2 MB 8.7 MB/s eta 0:00:01\n","     -------------------                      1.5/3.2 MB 8.8 MB/s eta 0:00:01\n","     -----------------------                  1.9/3.2 MB 8.5 MB/s eta 0:00:01\n","     ---------------------------              2.2/3.2 MB 8.2 MB/s eta 0:00:01\n","     --------------------------------         2.6/3.2 MB 8.3 MB/s eta 0:00:01\n","     ------------------------------------     2.9/3.2 MB 8.4 MB/s eta 0:00:01\n","     ---------------------------------------  3.2/3.2 MB 8.2 MB/s eta 0:00:01\n","     ---------------------------------------- 3.2/3.2 MB 7.6 MB/s eta 0:00:00\n","Requirement already satisfied: docutils<0.21 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sphinx-rtd-theme->indic-nlp-library) (0.20.1)\n","Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n","  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n","                                              0.0/121.1 kB ? eta -:--:--\n","     -------------------------------------- 121.1/121.1 kB 7.4 MB/s eta 0:00:00\n","Requirement already satisfied: six>=1.5 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.16.0)\n","Collecting sphinxcontrib-applehelp (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n","  Downloading sphinxcontrib_applehelp-1.0.8-py3-none-any.whl (120 kB)\n","                                              0.0/120.0 kB ? eta -:--:--\n","     -------------------------------------- 120.0/120.0 kB 7.3 MB/s eta 0:00:00\n","Collecting sphinxcontrib-devhelp (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n","  Downloading sphinxcontrib_devhelp-1.0.6-py3-none-any.whl (83 kB)\n","                                              0.0/83.5 kB ? eta -:--:--\n","     ---------------------------------------- 83.5/83.5 kB 4.9 MB/s eta 0:00:00\n","Collecting sphinxcontrib-jsmath (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n","  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n","Collecting sphinxcontrib-htmlhelp>=2.0.0 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n","  Downloading sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl (99 kB)\n","                                              0.0/99.2 kB ? eta -:--:--\n","     ---------------------------------------- 99.2/99.2 kB 5.9 MB/s eta 0:00:00\n","Collecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n","  Downloading sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl (92 kB)\n","                                              0.0/92.7 kB ? eta -:--:--\n","     ---------------------------------------- 92.7/92.7 kB 5.2 MB/s eta 0:00:00\n","Collecting sphinxcontrib-qthelp (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n","  Downloading sphinxcontrib_qthelp-1.0.7-py3-none-any.whl (89 kB)\n","                                              0.0/89.4 kB ? eta -:--:--\n","     ---------------------------------------- 89.4/89.4 kB 5.0 MB/s eta 0:00:00\n","Requirement already satisfied: Jinja2>=3.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\n","Requirement already satisfied: Pygments>=2.14 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.15.1)\n","Collecting snowballstemmer>=2.0 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n","  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n","                                              0.0/93.0 kB ? eta -:--:--\n","     ---------------------------------------- 93.0/93.0 kB ? eta 0:00:00\n","Collecting babel>=2.9 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n","  Downloading Babel-2.14.0-py3-none-any.whl (11.0 MB)\n","                                              0.0/11.0 MB ? eta -:--:--\n","     -                                        0.4/11.0 MB 11.6 MB/s eta 0:00:01\n","     --                                       0.7/11.0 MB 11.9 MB/s eta 0:00:01\n","     ---                                      1.0/11.0 MB 8.2 MB/s eta 0:00:02\n","     -----                                    1.5/11.0 MB 8.6 MB/s eta 0:00:02\n","     ------                                   1.8/11.0 MB 8.8 MB/s eta 0:00:02\n","     -------                                  2.1/11.0 MB 8.5 MB/s eta 0:00:02\n","     ---------                                2.5/11.0 MB 8.6 MB/s eta 0:00:01\n","     ----------                               2.8/11.0 MB 8.2 MB/s eta 0:00:02\n","     -----------                              3.2/11.0 MB 8.2 MB/s eta 0:00:01\n","     ------------                             3.6/11.0 MB 8.1 MB/s eta 0:00:01\n","     --------------                           3.9/11.0 MB 8.1 MB/s eta 0:00:01\n","     ---------------                          4.3/11.0 MB 8.0 MB/s eta 0:00:01\n","     ----------------                         4.6/11.0 MB 8.0 MB/s eta 0:00:01\n","     ------------------                       5.0/11.0 MB 8.0 MB/s eta 0:00:01\n","     -------------------                      5.4/11.0 MB 8.0 MB/s eta 0:00:01\n","     --------------------                     5.7/11.0 MB 7.9 MB/s eta 0:00:01\n","     ---------------------                    6.1/11.0 MB 7.9 MB/s eta 0:00:01\n","     -----------------------                  6.3/11.0 MB 8.0 MB/s eta 0:00:01\n","     ------------------------                 6.8/11.0 MB 7.9 MB/s eta 0:00:01\n","     -------------------------                7.1/11.0 MB 7.8 MB/s eta 0:00:01\n","     ---------------------------              7.5/11.0 MB 7.8 MB/s eta 0:00:01\n","     ----------------------------             7.9/11.0 MB 7.9 MB/s eta 0:00:01\n","     -----------------------------            8.2/11.0 MB 7.8 MB/s eta 0:00:01\n","     ------------------------------           8.5/11.0 MB 7.8 MB/s eta 0:00:01\n","     --------------------------------         8.9/11.0 MB 7.8 MB/s eta 0:00:01\n","     ---------------------------------        9.2/11.0 MB 7.8 MB/s eta 0:00:01\n","     ----------------------------------       9.5/11.0 MB 7.8 MB/s eta 0:00:01\n","     ------------------------------------     9.9/11.0 MB 7.8 MB/s eta 0:00:01\n","     -------------------------------------    10.3/11.0 MB 7.7 MB/s eta 0:00:01\n","     --------------------------------------   10.7/11.0 MB 7.6 MB/s eta 0:00:01\n","     ---------------------------------------  11.0/11.0 MB 7.7 MB/s eta 0:00:01\n","     ---------------------------------------  11.0/11.0 MB 7.6 MB/s eta 0:00:01\n","     ---------------------------------------- 11.0/11.0 MB 7.2 MB/s eta 0:00:00\n","Collecting alabaster<0.8,>=0.7 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n","  Downloading alabaster-0.7.16-py3-none-any.whl (13 kB)\n","Collecting imagesize>=1.3 (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n","  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n","Requirement already satisfied: requests>=2.25.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.31.0)\n","Requirement already satisfied: packaging>=21.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (23.1)\n","Requirement already satisfied: importlib-metadata>=4.8 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (6.6.0)\n","Requirement already satisfied: colorama>=0.4.5 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.4.6)\n","Requirement already satisfied: zipp>=0.5 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from importlib-metadata>=4.8->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.15.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from Jinja2>=3.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2023.7.22)\n","Installing collected packages: snowballstemmer, morfessor, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, imagesize, babel, alabaster, sphinx, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n","Successfully installed alabaster-0.7.16 babel-2.14.0 imagesize-1.4.1 indic-nlp-library-0.92 morfessor-2.0.6 snowballstemmer-2.2.0 sphinx-7.2.6 sphinx-argparse-0.4.0 sphinx-rtd-theme-2.0.0 sphinxcontrib-applehelp-1.0.8 sphinxcontrib-devhelp-1.0.6 sphinxcontrib-htmlhelp-2.0.5 sphinxcontrib-jquery-4.1 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.7 sphinxcontrib-serializinghtml-1.1.10\n"]}],"source":["!pip install indic-nlp-library\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:38:55.328476Z","iopub.status.busy":"2024-03-22T01:38:55.327983Z","iopub.status.idle":"2024-03-22T01:38:55.391491Z","shell.execute_reply":"2024-03-22T01:38:55.390388Z","shell.execute_reply.started":"2024-03-22T01:38:55.328432Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>4</th>\n","      <th>3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Woman in a black dress walking on the street.</td>\n","      <td>A woman watches a dog jump down the stairs.</td>\n","      <td>0.80</td>\n","      <td>['एक महिला एक कुत्ता को सीढ़ियों से नीचे उछलने...</td>\n","      <td>['सड़क पर घूमते हुए काले कपड़े पहने हुए एक महि...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A man and a woman looking at the camera.</td>\n","      <td>A man and a woman laughing.</td>\n","      <td>2.33</td>\n","      <td>['एक आदमी और एक औरत हंस रहे हैं।']</td>\n","      <td>['एक पुरुष और एक महिला कैमरा देख रही हैं।']</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>a brown dog running through the dirty muddy grass</td>\n","      <td>The large brown dog is running outside in the ...</td>\n","      <td>3.60</td>\n","      <td>['बड़े भूरे कुत्ते बाहर रेत में दौड़ रहे हैं।']</td>\n","      <td>['एक भूरा कुत्ता गंदगी में दौड़ता है']</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Three dogs pulling a man on a bicycle through ...</td>\n","      <td>The dogs are pulling a man on a type of bike, ...</td>\n","      <td>5.00</td>\n","      <td>['कुत्ते बर्फ के बीच एक आदमी को एक प्रकार के स...</td>\n","      <td>['तीन कुत्ते बर्फ के बीच एक आदमी को सायकल पर ख...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A baby in a red hat sitting in a stroller is h...</td>\n","      <td>A man in a gray shirt sitting in a field of fl...</td>\n","      <td>0.00</td>\n","      <td>['फूलों के मैदान में बैठा एक धूसर कुर्ता पहना ...</td>\n","      <td>['एक लाल टोपी पहने हुए बच्चे जो स्ट्रोलर में ब...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   0  \\\n","0      Woman in a black dress walking on the street.   \n","1           A man and a woman looking at the camera.   \n","2  a brown dog running through the dirty muddy grass   \n","3  Three dogs pulling a man on a bicycle through ...   \n","4  A baby in a red hat sitting in a stroller is h...   \n","\n","                                                   1     2  \\\n","0        A woman watches a dog jump down the stairs.  0.80   \n","1                        A man and a woman laughing.  2.33   \n","2  The large brown dog is running outside in the ...  3.60   \n","3  The dogs are pulling a man on a type of bike, ...  5.00   \n","4  A man in a gray shirt sitting in a field of fl...  0.00   \n","\n","                                                   4  \\\n","0  ['एक महिला एक कुत्ता को सीढ़ियों से नीचे उछलने...   \n","1                 ['एक आदमी और एक औरत हंस रहे हैं।']   \n","2    ['बड़े भूरे कुत्ते बाहर रेत में दौड़ रहे हैं।']   \n","3  ['कुत्ते बर्फ के बीच एक आदमी को एक प्रकार के स...   \n","4  ['फूलों के मैदान में बैठा एक धूसर कुर्ता पहना ...   \n","\n","                                                   3  \n","0  ['सड़क पर घूमते हुए काले कपड़े पहने हुए एक महि...  \n","1        ['एक पुरुष और एक महिला कैमरा देख रही हैं।']  \n","2             ['एक भूरा कुत्ता गंदगी में दौड़ता है']  \n","3  ['तीन कुत्ते बर्फ के बीच एक आदमी को सायकल पर ख...  \n","4  ['एक लाल टोपी पहने हुए बच्चे जो स्ट्रोलर में ब...  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","df=pd.read_csv('mid.csv')\n","df.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:38:55.393700Z","iopub.status.busy":"2024-03-22T01:38:55.393318Z","iopub.status.idle":"2024-03-22T01:38:55.406017Z","shell.execute_reply":"2024-03-22T01:38:55.404715Z","shell.execute_reply.started":"2024-03-22T01:38:55.393638Z"},"trusted":true},"outputs":[],"source":["df=df.drop(columns=['1','0'])"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:38:55.408890Z","iopub.status.busy":"2024-03-22T01:38:55.407784Z","iopub.status.idle":"2024-03-22T01:38:55.427509Z","shell.execute_reply":"2024-03-22T01:38:55.426551Z","shell.execute_reply.started":"2024-03-22T01:38:55.408854Z"},"trusted":true},"outputs":[],"source":["stopwords_hi = ['तुम','मेरी','मुझे','क्योंकि','हम','प्रति','अबकी','आगे','माननीय','शहर','बताएं','कौनसी','क्लिक','किसकी','बड़े','मैं','and','रही','आज','लें','आपके','मिलकर','सब','मेरे','जी','श्री','वैसा','आपका','अंदर', 'अत', 'अपना', 'अपनी', 'अपने', 'अभी', 'आदि', 'आप', 'इत्यादि', 'इन', 'इनका', 'इन्हीं', 'इन्हें', 'इन्हों', 'इस', 'इसका', 'इसकी', 'इसके', 'इसमें', 'इसी', 'इसे', 'उन', 'उनका', 'उनकी', 'उनके', 'उनको', 'उन्हीं', 'उन्हें', 'उन्हों', 'उस', 'उसके', 'उसी', 'उसे', 'एक', 'एवं', 'एस', 'ऐसे', 'और', 'कई', 'कर','करता', 'करते', 'करना', 'करने', 'करें', 'कहते', 'कहा', 'का', 'काफ़ी', 'कि', 'कितना', 'किन्हें', 'किन्हों', 'किया', 'किर', 'किस', 'किसी', 'किसे', 'की', 'कुछ', 'कुल', 'के', 'को', 'कोई', 'कौन', 'कौनसा', 'गया', 'घर', 'जब', 'जहाँ', 'जा', 'जितना', 'जिन', 'जिन्हें', 'जिन्हों', 'जिस', 'जिसे', 'जीधर', 'जैसा', 'जैसे', 'जो', 'तक', 'तब', 'तरह', 'तिन', 'तिन्हें', 'तिन्हों', 'तिस', 'तिसे', 'तो', 'था', 'थी', 'थे', 'दबारा', 'दिया', 'दुसरा', 'दूसरे', 'दो', 'द्वारा', 'न', 'नहीं', 'ना', 'निहायत', 'नीचे', 'ने', 'पर', 'पर', 'पहले', 'पूरा', 'पे', 'फिर', 'बनी', 'बही', 'बहुत', 'बाद', 'बाला', 'बिलकुल', 'भी', 'भीतर', 'मगर', 'मानो', 'मे', 'में', 'यदि', 'यह', 'यहाँ', 'यही', 'या', 'यिह', 'ये', 'रखें', 'रहा', 'रहे', 'ऱ्वासा', 'लिए', 'लिये', 'लेकिन', 'व', 'वर्ग', 'वह', 'वह', 'वहाँ', 'वहीं', 'वाले', 'वुह', 'वे', 'वग़ैरह', 'संग', 'सकता', 'सकते', 'सबसे', 'सभी', 'साथ', 'साबुत', 'साभ', 'सारा', 'से', 'सो', 'ही', 'हुआ', 'हुई', 'हुए', 'है', 'हैं', 'हो', 'होता', 'होती', 'होते', 'होना', 'होने', 'अपनि', 'जेसे', 'होति', 'सभि', 'तिंहों', 'इंहों', 'दवारा', 'इसि', 'किंहें', 'थि', 'उंहों', 'ओर', 'जिंहें', 'वहिं', 'अभि', 'बनि', 'हि', 'उंहिं', 'उंहें', 'हें', 'वगेरह', 'एसे', 'रवासा', 'कोन', 'निचे', 'काफि', 'उसि', 'पुरा', 'भितर', 'हे', 'बहि', 'वहां', 'कोइ', 'यहां', 'जिंहों', 'तिंहें', 'किसि', 'कइ', 'यहि', 'इंहिं', 'जिधर', 'इंहें', 'अदि', 'इतयादि', 'हुइ', 'कोनसा', 'इसकि', 'दुसरे', 'जहां', 'अप', 'किंहों', 'उनकि', 'भि', 'वरग', 'हुअ', 'जेसा', 'नहिं']\n","punctuations = ['nn','n', '।','/', '`', '+', '\\\\', '\"', '?', '▁(', '$', '@', '[', '_', \"'\", '!', ',', ':', '^', '|', ']', '=', '%', '&', '.', ')', '(', '#', '*', '', ';', '-', '}','|','\"']"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:38:55.429617Z","iopub.status.busy":"2024-03-22T01:38:55.428826Z","iopub.status.idle":"2024-03-22T01:38:55.453492Z","shell.execute_reply":"2024-03-22T01:38:55.452557Z","shell.execute_reply.started":"2024-03-22T01:38:55.429576Z"},"trusted":true},"outputs":[],"source":["from indicnlp.tokenize import indic_tokenize\n","def tokenization(indic_string):\n","    tokens = []\n","    for t in indic_tokenize.trivial_tokenize(indic_string):\n","        tokens.append(t)\n","    return tokens\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:38:55.455491Z","iopub.status.busy":"2024-03-22T01:38:55.455136Z","iopub.status.idle":"2024-03-22T01:38:55.604334Z","shell.execute_reply":"2024-03-22T01:38:55.603158Z","shell.execute_reply.started":"2024-03-22T01:38:55.455452Z"},"trusted":true},"outputs":[],"source":["df['3']=df['3'].apply(lambda x: tokenization(x))\n","df['4']=df['4'].apply(lambda x: tokenization(x))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:38:55.609184Z","iopub.status.busy":"2024-03-22T01:38:55.608795Z","iopub.status.idle":"2024-03-22T01:38:55.614122Z","shell.execute_reply":"2024-03-22T01:38:55.613228Z","shell.execute_reply.started":"2024-03-22T01:38:55.609153Z"},"trusted":true},"outputs":[],"source":["to_be_removed = stopwords_hi + punctuations \n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:38:55.615902Z","iopub.status.busy":"2024-03-22T01:38:55.615426Z","iopub.status.idle":"2024-03-22T01:40:37.361591Z","shell.execute_reply":"2024-03-22T01:40:37.360394Z","shell.execute_reply.started":"2024-03-22T01:38:55.615860Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>4</th>\n","      <th>3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1840</th>\n","      <td>3.333</td>\n","      <td>[[, ', एक, आदमी, एक, डिजिटल, शुष्क, मिटाने, के...</td>\n","      <td>[आदमी, रेखांकन]</td>\n","    </tr>\n","    <tr>\n","      <th>1841</th>\n","      <td>2.000</td>\n","      <td>[[, ', बंदर, branch, to, branch, से, झुका, हुआ...</td>\n","      <td>[बंदर, पेड़ों, झुक]</td>\n","    </tr>\n","    <tr>\n","      <th>1842</th>\n","      <td>3.000</td>\n","      <td>[[, ', दो, लड़के, टर्मिनल, पर, खेल, रहे, हैं, ...</td>\n","      <td>[बच्चे, टर्मोलाइन, चढ़]</td>\n","    </tr>\n","    <tr>\n","      <th>1843</th>\n","      <td>4.000</td>\n","      <td>[[, ', एक, महिला, जो, हरी, पीपल, का, टुकड़ा, क...</td>\n","      <td>[मादा, चाकू, चावल, टुकड़ा, काट]</td>\n","    </tr>\n","    <tr>\n","      <th>1844</th>\n","      <td>2.000</td>\n","      <td>[[, ', एक, आदमी, एक, कार, में, anti, -, freeze...</td>\n","      <td>[आदमी, कार, तेल, जोड़]</td>\n","    </tr>\n","    <tr>\n","      <th>1845</th>\n","      <td>0.400</td>\n","      <td>[[, ', एक, आदमी, रस्सी, पर, चढ़, रहा, है, ।, '...</td>\n","      <td>[आदमी, मशीन, carrot, टुकड़ा]</td>\n","    </tr>\n","    <tr>\n","      <th>1846</th>\n","      <td>3.200</td>\n","      <td>[[, ', एक, व्यक्ति, एक, 피아노, कीबोर्ड, बजा, रहा...</td>\n","      <td>[लड़के, कुंजीपट, बजाया]</td>\n","    </tr>\n","    <tr>\n","      <th>1847</th>\n","      <td>0.400</td>\n","      <td>[[, ', एक, लड़का, मिट्टी, में, खेल, रहा, है, ।...</td>\n","      <td>[बिल्ली, एंटिना, खेल]</td>\n","    </tr>\n","    <tr>\n","      <th>1848</th>\n","      <td>2.000</td>\n","      <td>[[, ', एक, व्यक्ति, कंटालूप, का, टुकड़ा, कर, र...</td>\n","      <td>[महिला, मक्खन, काट]</td>\n","    </tr>\n","    <tr>\n","      <th>1849</th>\n","      <td>4.500</td>\n","      <td>[[, ', कुछ, लोग, चट्टान, से, एक, dummy, को, फे...</td>\n","      <td>[लोगों, डमी, चट्टान, किनारे, फेंक]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          2                                                  4  \\\n","1840  3.333  [[, ', एक, आदमी, एक, डिजिटल, शुष्क, मिटाने, के...   \n","1841  2.000  [[, ', बंदर, branch, to, branch, से, झुका, हुआ...   \n","1842  3.000  [[, ', दो, लड़के, टर्मिनल, पर, खेल, रहे, हैं, ...   \n","1843  4.000  [[, ', एक, महिला, जो, हरी, पीपल, का, टुकड़ा, क...   \n","1844  2.000  [[, ', एक, आदमी, एक, कार, में, anti, -, freeze...   \n","1845  0.400  [[, ', एक, आदमी, रस्सी, पर, चढ़, रहा, है, ।, '...   \n","1846  3.200  [[, ', एक, व्यक्ति, एक, 피아노, कीबोर्ड, बजा, रहा...   \n","1847  0.400  [[, ', एक, लड़का, मिट्टी, में, खेल, रहा, है, ।...   \n","1848  2.000  [[, ', एक, व्यक्ति, कंटालूप, का, टुकड़ा, कर, र...   \n","1849  4.500  [[, ', कुछ, लोग, चट्टान, से, एक, dummy, को, फे...   \n","\n","                                       3  \n","1840                     [आदमी, रेखांकन]  \n","1841                 [बंदर, पेड़ों, झुक]  \n","1842             [बच्चे, टर्मोलाइन, चढ़]  \n","1843     [मादा, चाकू, चावल, टुकड़ा, काट]  \n","1844              [आदमी, कार, तेल, जोड़]  \n","1845        [आदमी, मशीन, carrot, टुकड़ा]  \n","1846             [लड़के, कुंजीपट, बजाया]  \n","1847               [बिल्ली, एंटिना, खेल]  \n","1848                 [महिला, मक्खन, काट]  \n","1849  [लोगों, डमी, चट्टान, किनारे, फेंक]  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["mask = df['3'].apply(lambda x: x not in to_be_removed)\n","df.loc[mask, '3'] = df.loc[mask, '3'].apply(lambda x: [ele for ele in x if ele not in to_be_removed])\n","\n","df.tail(10)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:40:37.363497Z","iopub.status.busy":"2024-03-22T01:40:37.363140Z","iopub.status.idle":"2024-03-22T01:40:37.380983Z","shell.execute_reply":"2024-03-22T01:40:37.379846Z","shell.execute_reply.started":"2024-03-22T01:40:37.363467Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>4</th>\n","      <th>3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.80</td>\n","      <td>[[, ', एक, महिला, एक, कुत्ता, को, सीढ़ियों, से...</td>\n","      <td>[सड़क, घूमते, काले, कपड़े, पहने, महिला]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.33</td>\n","      <td>[[, ', एक, आदमी, और, एक, औरत, हंस, रहे, हैं, ।...</td>\n","      <td>[पुरुष, महिला, कैमरा, देख]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.60</td>\n","      <td>[[, ', बड़े, भूरे, कुत्ते, बाहर, रेत, में, दौड...</td>\n","      <td>[भूरा, कुत्ता, गंदगी, दौड़ता]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5.00</td>\n","      <td>[[, ', कुत्ते, बर्फ, के, बीच, एक, आदमी, को, एक...</td>\n","      <td>[तीन, कुत्ते, बर्फ, बीच, आदमी, सायकल, खींचते]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.00</td>\n","      <td>[[, ', फूलों, के, मैदान, में, बैठा, एक, धूसर, ...</td>\n","      <td>[लाल, टोपी, पहने, बच्चे, स्ट्रोलर, बैठा, पुतली...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      2                                                  4  \\\n","0  0.80  [[, ', एक, महिला, एक, कुत्ता, को, सीढ़ियों, से...   \n","1  2.33  [[, ', एक, आदमी, और, एक, औरत, हंस, रहे, हैं, ।...   \n","2  3.60  [[, ', बड़े, भूरे, कुत्ते, बाहर, रेत, में, दौड...   \n","3  5.00  [[, ', कुत्ते, बर्फ, के, बीच, एक, आदमी, को, एक...   \n","4  0.00  [[, ', फूलों, के, मैदान, में, बैठा, एक, धूसर, ...   \n","\n","                                                   3  \n","0            [सड़क, घूमते, काले, कपड़े, पहने, महिला]  \n","1                         [पुरुष, महिला, कैमरा, देख]  \n","2                      [भूरा, कुत्ता, गंदगी, दौड़ता]  \n","3      [तीन, कुत्ते, बर्फ, बीच, आदमी, सायकल, खींचते]  \n","4  [लाल, टोपी, पहने, बच्चे, स्ट्रोलर, बैठा, पुतली...  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:40:37.382795Z","iopub.status.busy":"2024-03-22T01:40:37.382428Z","iopub.status.idle":"2024-03-22T01:42:18.030915Z","shell.execute_reply":"2024-03-22T01:42:18.029743Z","shell.execute_reply.started":"2024-03-22T01:40:37.382754Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>4</th>\n","      <th>3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1840</th>\n","      <td>3.333</td>\n","      <td>[आदमी, डिजिटल, शुष्क, मिटाने, बोर्ड, चित्र, बना]</td>\n","      <td>[आदमी, रेखांकन]</td>\n","    </tr>\n","    <tr>\n","      <th>1841</th>\n","      <td>2.000</td>\n","      <td>[बंदर, branch, to, branch, झुका]</td>\n","      <td>[बंदर, पेड़ों, झुक]</td>\n","    </tr>\n","    <tr>\n","      <th>1842</th>\n","      <td>3.000</td>\n","      <td>[लड़के, टर्मिनल, खेल]</td>\n","      <td>[बच्चे, टर्मोलाइन, चढ़]</td>\n","    </tr>\n","    <tr>\n","      <th>1843</th>\n","      <td>4.000</td>\n","      <td>[महिला, हरी, पीपल, टुकड़ा, काटती]</td>\n","      <td>[मादा, चाकू, चावल, टुकड़ा, काट]</td>\n","    </tr>\n","    <tr>\n","      <th>1844</th>\n","      <td>2.000</td>\n","      <td>[आदमी, कार, anti, freeze, डाल]</td>\n","      <td>[आदमी, कार, तेल, जोड़]</td>\n","    </tr>\n","    <tr>\n","      <th>1845</th>\n","      <td>0.400</td>\n","      <td>[आदमी, रस्सी, चढ़]</td>\n","      <td>[आदमी, मशीन, carrot, टुकड़ा]</td>\n","    </tr>\n","    <tr>\n","      <th>1846</th>\n","      <td>3.200</td>\n","      <td>[व्यक्ति, 피아노, कीबोर्ड, बजा]</td>\n","      <td>[लड़के, कुंजीपट, बजाया]</td>\n","    </tr>\n","    <tr>\n","      <th>1847</th>\n","      <td>0.400</td>\n","      <td>[लड़का, मिट्टी, खेल]</td>\n","      <td>[बिल्ली, एंटिना, खेल]</td>\n","    </tr>\n","    <tr>\n","      <th>1848</th>\n","      <td>2.000</td>\n","      <td>[व्यक्ति, कंटालूप, टुकड़ा]</td>\n","      <td>[महिला, मक्खन, काट]</td>\n","    </tr>\n","    <tr>\n","      <th>1849</th>\n","      <td>4.500</td>\n","      <td>[लोग, चट्टान, dummy, फेंक]</td>\n","      <td>[लोगों, डमी, चट्टान, किनारे, फेंक]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          2                                                 4  \\\n","1840  3.333  [आदमी, डिजिटल, शुष्क, मिटाने, बोर्ड, चित्र, बना]   \n","1841  2.000                  [बंदर, branch, to, branch, झुका]   \n","1842  3.000                             [लड़के, टर्मिनल, खेल]   \n","1843  4.000                 [महिला, हरी, पीपल, टुकड़ा, काटती]   \n","1844  2.000                    [आदमी, कार, anti, freeze, डाल]   \n","1845  0.400                                [आदमी, रस्सी, चढ़]   \n","1846  3.200                      [व्यक्ति, 피아노, कीबोर्ड, बजा]   \n","1847  0.400                              [लड़का, मिट्टी, खेल]   \n","1848  2.000                        [व्यक्ति, कंटालूप, टुकड़ा]   \n","1849  4.500                        [लोग, चट्टान, dummy, फेंक]   \n","\n","                                       3  \n","1840                     [आदमी, रेखांकन]  \n","1841                 [बंदर, पेड़ों, झुक]  \n","1842             [बच्चे, टर्मोलाइन, चढ़]  \n","1843     [मादा, चाकू, चावल, टुकड़ा, काट]  \n","1844              [आदमी, कार, तेल, जोड़]  \n","1845        [आदमी, मशीन, carrot, टुकड़ा]  \n","1846             [लड़के, कुंजीपट, बजाया]  \n","1847               [बिल्ली, एंटिना, खेल]  \n","1848                 [महिला, मक्खन, काट]  \n","1849  [लोगों, डमी, चट्टान, किनारे, फेंक]  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["\n","mask = df['4'].apply(lambda x: x not in to_be_removed)\n","df.loc[mask, '4'] = df.loc[mask, '4'].apply(lambda x: [ele for ele in x if ele not in to_be_removed])\n","\n","df.tail(10)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:42:18.032853Z","iopub.status.busy":"2024-03-22T01:42:18.032448Z","iopub.status.idle":"2024-03-22T01:42:18.039020Z","shell.execute_reply":"2024-03-22T01:42:18.037741Z","shell.execute_reply.started":"2024-03-22T01:42:18.032823Z"},"trusted":true},"outputs":[],"source":["def joining(lixt):\n","    return \" \".join(lixt)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:42:18.041204Z","iopub.status.busy":"2024-03-22T01:42:18.040744Z","iopub.status.idle":"2024-03-22T01:42:18.059645Z","shell.execute_reply":"2024-03-22T01:42:18.058556Z","shell.execute_reply.started":"2024-03-22T01:42:18.041176Z"},"trusted":true},"outputs":[],"source":["df['5']=df['3'].apply(joining)\n","df['6']=df['4'].apply(joining)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:42:18.061512Z","iopub.status.busy":"2024-03-22T01:42:18.061172Z","iopub.status.idle":"2024-03-22T01:42:18.090810Z","shell.execute_reply":"2024-03-22T01:42:18.089653Z","shell.execute_reply.started":"2024-03-22T01:42:18.061481Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>4</th>\n","      <th>3</th>\n","      <th>5</th>\n","      <th>6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.80</td>\n","      <td>[महिला, कुत्ता, सीढ़ियों, उछलने, देखती]</td>\n","      <td>[सड़क, घूमते, काले, कपड़े, पहने, महिला]</td>\n","      <td>सड़क घूमते काले कपड़े पहने महिला</td>\n","      <td>महिला कुत्ता सीढ़ियों उछलने देखती</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.33</td>\n","      <td>[आदमी, औरत, हंस]</td>\n","      <td>[पुरुष, महिला, कैमरा, देख]</td>\n","      <td>पुरुष महिला कैमरा देख</td>\n","      <td>आदमी औरत हंस</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.60</td>\n","      <td>[बड़े, भूरे, कुत्ते, बाहर, रेत, दौड़]</td>\n","      <td>[भूरा, कुत्ता, गंदगी, दौड़ता]</td>\n","      <td>भूरा कुत्ता गंदगी दौड़ता</td>\n","      <td>बड़े भूरे कुत्ते बाहर रेत दौड़</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5.00</td>\n","      <td>[कुत्ते, बर्फ, बीच, आदमी, प्रकार, साइकिल, खींच]</td>\n","      <td>[तीन, कुत्ते, बर्फ, बीच, आदमी, सायकल, खींचते]</td>\n","      <td>तीन कुत्ते बर्फ बीच आदमी सायकल खींचते</td>\n","      <td>कुत्ते बर्फ बीच आदमी प्रकार साइकिल खींच</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.00</td>\n","      <td>[फूलों, मैदान, बैठा, धूसर, कुर्ता, पहना, आदमी]</td>\n","      <td>[लाल, टोपी, पहने, बच्चे, स्ट्रोलर, बैठा, पुतली...</td>\n","      <td>लाल टोपी पहने बच्चे स्ट्रोलर बैठा पुतली पकड़</td>\n","      <td>फूलों मैदान बैठा धूसर कुर्ता पहना आदमी</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      2                                                4  \\\n","0  0.80          [महिला, कुत्ता, सीढ़ियों, उछलने, देखती]   \n","1  2.33                                 [आदमी, औरत, हंस]   \n","2  3.60            [बड़े, भूरे, कुत्ते, बाहर, रेत, दौड़]   \n","3  5.00  [कुत्ते, बर्फ, बीच, आदमी, प्रकार, साइकिल, खींच]   \n","4  0.00   [फूलों, मैदान, बैठा, धूसर, कुर्ता, पहना, आदमी]   \n","\n","                                                   3  \\\n","0            [सड़क, घूमते, काले, कपड़े, पहने, महिला]   \n","1                         [पुरुष, महिला, कैमरा, देख]   \n","2                      [भूरा, कुत्ता, गंदगी, दौड़ता]   \n","3      [तीन, कुत्ते, बर्फ, बीच, आदमी, सायकल, खींचते]   \n","4  [लाल, टोपी, पहने, बच्चे, स्ट्रोलर, बैठा, पुतली...   \n","\n","                                              5  \\\n","0              सड़क घूमते काले कपड़े पहने महिला   \n","1                         पुरुष महिला कैमरा देख   \n","2                      भूरा कुत्ता गंदगी दौड़ता   \n","3         तीन कुत्ते बर्फ बीच आदमी सायकल खींचते   \n","4  लाल टोपी पहने बच्चे स्ट्रोलर बैठा पुतली पकड़   \n","\n","                                         6  \n","0        महिला कुत्ता सीढ़ियों उछलने देखती  \n","1                             आदमी औरत हंस  \n","2           बड़े भूरे कुत्ते बाहर रेत दौड़  \n","3  कुत्ते बर्फ बीच आदमी प्रकार साइकिल खींच  \n","4   फूलों मैदान बैठा धूसर कुर्ता पहना आदमी  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:42:18.093141Z","iopub.status.busy":"2024-03-22T01:42:18.092787Z","iopub.status.idle":"2024-03-22T01:42:32.294492Z","shell.execute_reply":"2024-03-22T01:42:32.292948Z","shell.execute_reply.started":"2024-03-22T01:42:18.093113Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import AutoModel, AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert')\n","\n","model = AutoModel.from_pretrained('ai4bharat/indic-bert')"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:42:32.297103Z","iopub.status.busy":"2024-03-22T01:42:32.296443Z","iopub.status.idle":"2024-03-22T01:42:32.304306Z","shell.execute_reply":"2024-03-22T01:42:32.302995Z","shell.execute_reply.started":"2024-03-22T01:42:32.297059Z"},"trusted":true},"outputs":[],"source":["def word_em(text):    \n","    encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n","    word_embeddings = model(**encoded_input).last_hidden_state\n","    sentence_embedding = word_embeddings.mean(dim=1)\n","    return sentence_embedding"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:42:32.306808Z","iopub.status.busy":"2024-03-22T01:42:32.306323Z","iopub.status.idle":"2024-03-22T01:46:19.055361Z","shell.execute_reply":"2024-03-22T01:46:19.054020Z","shell.execute_reply.started":"2024-03-22T01:42:32.306767Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]}],"source":["df['5']=df['5'].apply(word_em)\n","df['6']=df['6'].apply(word_em)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:46:19.061526Z","iopub.status.busy":"2024-03-22T01:46:19.060822Z","iopub.status.idle":"2024-03-22T01:46:19.638806Z","shell.execute_reply":"2024-03-22T01:46:19.637528Z","shell.execute_reply.started":"2024-03-22T01:46:19.061482Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>4</th>\n","      <th>3</th>\n","      <th>5</th>\n","      <th>6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.80</td>\n","      <td>[महिला, कुत्ता, सीढ़ियों, उछलने, देखती]</td>\n","      <td>[सड़क, घूमते, काले, कपड़े, पहने, महिला]</td>\n","      <td>[[tensor(0.1311, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","      <td>[[tensor(0.0086, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.33</td>\n","      <td>[आदमी, औरत, हंस]</td>\n","      <td>[पुरुष, महिला, कैमरा, देख]</td>\n","      <td>[[tensor(0.3081, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","      <td>[[tensor(-0.0399, grad_fn=&lt;UnbindBackward0&gt;), ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.60</td>\n","      <td>[बड़े, भूरे, कुत्ते, बाहर, रेत, दौड़]</td>\n","      <td>[भूरा, कुत्ता, गंदगी, दौड़ता]</td>\n","      <td>[[tensor(0.2829, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","      <td>[[tensor(0.2920, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5.00</td>\n","      <td>[कुत्ते, बर्फ, बीच, आदमी, प्रकार, साइकिल, खींच]</td>\n","      <td>[तीन, कुत्ते, बर्फ, बीच, आदमी, सायकल, खींचते]</td>\n","      <td>[[tensor(0.1059, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","      <td>[[tensor(0.2275, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.00</td>\n","      <td>[फूलों, मैदान, बैठा, धूसर, कुर्ता, पहना, आदमी]</td>\n","      <td>[लाल, टोपी, पहने, बच्चे, स्ट्रोलर, बैठा, पुतली...</td>\n","      <td>[[tensor(0.0699, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","      <td>[[tensor(0.0499, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      2                                                4  \\\n","0  0.80          [महिला, कुत्ता, सीढ़ियों, उछलने, देखती]   \n","1  2.33                                 [आदमी, औरत, हंस]   \n","2  3.60            [बड़े, भूरे, कुत्ते, बाहर, रेत, दौड़]   \n","3  5.00  [कुत्ते, बर्फ, बीच, आदमी, प्रकार, साइकिल, खींच]   \n","4  0.00   [फूलों, मैदान, बैठा, धूसर, कुर्ता, पहना, आदमी]   \n","\n","                                                   3  \\\n","0            [सड़क, घूमते, काले, कपड़े, पहने, महिला]   \n","1                         [पुरुष, महिला, कैमरा, देख]   \n","2                      [भूरा, कुत्ता, गंदगी, दौड़ता]   \n","3      [तीन, कुत्ते, बर्फ, बीच, आदमी, सायकल, खींचते]   \n","4  [लाल, टोपी, पहने, बच्चे, स्ट्रोलर, बैठा, पुतली...   \n","\n","                                                   5  \\\n","0  [[tensor(0.1311, grad_fn=<UnbindBackward0>), t...   \n","1  [[tensor(0.3081, grad_fn=<UnbindBackward0>), t...   \n","2  [[tensor(0.2829, grad_fn=<UnbindBackward0>), t...   \n","3  [[tensor(0.1059, grad_fn=<UnbindBackward0>), t...   \n","4  [[tensor(0.0699, grad_fn=<UnbindBackward0>), t...   \n","\n","                                                   6  \n","0  [[tensor(0.0086, grad_fn=<UnbindBackward0>), t...  \n","1  [[tensor(-0.0399, grad_fn=<UnbindBackward0>), ...  \n","2  [[tensor(0.2920, grad_fn=<UnbindBackward0>), t...  \n","3  [[tensor(0.2275, grad_fn=<UnbindBackward0>), t...  \n","4  [[tensor(0.0499, grad_fn=<UnbindBackward0>), t...  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:46:19.641461Z","iopub.status.busy":"2024-03-22T01:46:19.640716Z","iopub.status.idle":"2024-03-22T01:46:23.612931Z","shell.execute_reply":"2024-03-22T01:46:23.611768Z","shell.execute_reply.started":"2024-03-22T01:46:19.641418Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 16.0kB/s]\n","c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Gaurav B V\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n","vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 6.88MB/s]\n","tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 2.29MB/s]\n","config.json: 100%|██████████| 570/570 [00:00<00:00, 201kB/s]\n","model.safetensors: 100%|██████████| 440M/440M [00:33<00:00, 13.1MB/s] \n"]},{"name":"stdout","output_type":"stream","text":["Cosine Similarity: 0.28673091530799866\n"]}],"source":["from transformers import BertTokenizer, BertModel\n","import torch\n","\n","# Load pre-trained BERT model and tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","\n","# Example sentences\n","sentence1 = \"The cat sat on the mat.\"\n","sentence2 = \"the\"\n","\n","# Tokenize sentences and obtain input IDs\n","inputs1 = tokenizer(sentence1, return_tensors='pt', padding=True, truncation=True)\n","inputs2 = tokenizer(sentence2, return_tensors='pt', padding=True, truncation=True)\n","\n","# Obtain BERT embeddings\n","with torch.no_grad():\n","    outputs1 = model(**inputs1)\n","    outputs2 = model(**inputs2)\n","\n","# Extract [CLS] token embeddings (sentence embeddings)\n","sentence_embedding1 = outputs1.last_hidden_state.mean(dim=1)\n","sentence_embedding2 = outputs2.last_hidden_state.mean(dim=1)\n","\n","# Compute cosine similarity between sentence embeddings\n","cosine_sim = torch.nn.functional.cosine_similarity(sentence_embedding1, sentence_embedding2, dim=1)\n","\n","print(\"Cosine Similarity:\", cosine_sim.item())"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:46:23.615468Z","iopub.status.busy":"2024-03-22T01:46:23.614735Z","iopub.status.idle":"2024-03-22T01:46:23.621443Z","shell.execute_reply":"2024-03-22T01:46:23.620334Z","shell.execute_reply.started":"2024-03-22T01:46:23.615427Z"},"trusted":true},"outputs":[],"source":["def min_max_normalize(column):\n","    return (column - column.min()) / (column.max() - column.min())"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:46:23.624177Z","iopub.status.busy":"2024-03-22T01:46:23.622989Z","iopub.status.idle":"2024-03-22T01:46:24.992922Z","shell.execute_reply":"2024-03-22T01:46:24.991695Z","shell.execute_reply.started":"2024-03-22T01:46:23.624134Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","# Create a scaler object\n","scaler = MinMaxScaler()\n","# Fit the scaler to the 'similarity_score' column and transform it\n","df['2'] = scaler.fit_transform(df[['2']])"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:46:24.994834Z","iopub.status.busy":"2024-03-22T01:46:24.994437Z","iopub.status.idle":"2024-03-22T01:46:25.552767Z","shell.execute_reply":"2024-03-22T01:46:25.551482Z","shell.execute_reply.started":"2024-03-22T01:46:24.994802Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>4</th>\n","      <th>3</th>\n","      <th>5</th>\n","      <th>6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.160</td>\n","      <td>[महिला, कुत्ता, सीढ़ियों, उछलने, देखती]</td>\n","      <td>[सड़क, घूमते, काले, कपड़े, पहने, महिला]</td>\n","      <td>[[tensor(0.1311, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","      <td>[[tensor(0.0086, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.466</td>\n","      <td>[आदमी, औरत, हंस]</td>\n","      <td>[पुरुष, महिला, कैमरा, देख]</td>\n","      <td>[[tensor(0.3081, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","      <td>[[tensor(-0.0399, grad_fn=&lt;UnbindBackward0&gt;), ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.720</td>\n","      <td>[बड़े, भूरे, कुत्ते, बाहर, रेत, दौड़]</td>\n","      <td>[भूरा, कुत्ता, गंदगी, दौड़ता]</td>\n","      <td>[[tensor(0.2829, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","      <td>[[tensor(0.2920, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.000</td>\n","      <td>[कुत्ते, बर्फ, बीच, आदमी, प्रकार, साइकिल, खींच]</td>\n","      <td>[तीन, कुत्ते, बर्फ, बीच, आदमी, सायकल, खींचते]</td>\n","      <td>[[tensor(0.1059, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","      <td>[[tensor(0.2275, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000</td>\n","      <td>[फूलों, मैदान, बैठा, धूसर, कुर्ता, पहना, आदमी]</td>\n","      <td>[लाल, टोपी, पहने, बच्चे, स्ट्रोलर, बैठा, पुतली...</td>\n","      <td>[[tensor(0.0699, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","      <td>[[tensor(0.0499, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       2                                                4  \\\n","0  0.160          [महिला, कुत्ता, सीढ़ियों, उछलने, देखती]   \n","1  0.466                                 [आदमी, औरत, हंस]   \n","2  0.720            [बड़े, भूरे, कुत्ते, बाहर, रेत, दौड़]   \n","3  1.000  [कुत्ते, बर्फ, बीच, आदमी, प्रकार, साइकिल, खींच]   \n","4  0.000   [फूलों, मैदान, बैठा, धूसर, कुर्ता, पहना, आदमी]   \n","\n","                                                   3  \\\n","0            [सड़क, घूमते, काले, कपड़े, पहने, महिला]   \n","1                         [पुरुष, महिला, कैमरा, देख]   \n","2                      [भूरा, कुत्ता, गंदगी, दौड़ता]   \n","3      [तीन, कुत्ते, बर्फ, बीच, आदमी, सायकल, खींचते]   \n","4  [लाल, टोपी, पहने, बच्चे, स्ट्रोलर, बैठा, पुतली...   \n","\n","                                                   5  \\\n","0  [[tensor(0.1311, grad_fn=<UnbindBackward0>), t...   \n","1  [[tensor(0.3081, grad_fn=<UnbindBackward0>), t...   \n","2  [[tensor(0.2829, grad_fn=<UnbindBackward0>), t...   \n","3  [[tensor(0.1059, grad_fn=<UnbindBackward0>), t...   \n","4  [[tensor(0.0699, grad_fn=<UnbindBackward0>), t...   \n","\n","                                                   6  \n","0  [[tensor(0.0086, grad_fn=<UnbindBackward0>), t...  \n","1  [[tensor(-0.0399, grad_fn=<UnbindBackward0>), ...  \n","2  [[tensor(0.2920, grad_fn=<UnbindBackward0>), t...  \n","3  [[tensor(0.2275, grad_fn=<UnbindBackward0>), t...  \n","4  [[tensor(0.0499, grad_fn=<UnbindBackward0>), t...  "]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T02:02:29.363619Z","iopub.status.busy":"2024-03-22T02:02:29.363197Z","iopub.status.idle":"2024-03-22T02:02:29.368648Z","shell.execute_reply":"2024-03-22T02:02:29.367480Z","shell.execute_reply.started":"2024-03-22T02:02:29.363584Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import ast\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T02:05:51.379718Z","iopub.status.busy":"2024-03-22T02:05:51.379270Z","iopub.status.idle":"2024-03-22T02:05:51.403600Z","shell.execute_reply":"2024-03-22T02:05:51.402369Z","shell.execute_reply.started":"2024-03-22T02:05:51.379649Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n","\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["df['5'][0]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T02:03:16.483284Z","iopub.status.busy":"2024-03-22T02:03:16.482867Z","iopub.status.idle":"2024-03-22T02:03:16.930588Z","shell.execute_reply":"2024-03-22T02:03:16.928432Z","shell.execute_reply.started":"2024-03-22T02:03:16.483255Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[6], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[idx]\n\u001b[1;32m---> 37\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import DataLoader, Dataset\n","\n","class SiameseNetwork(nn.Module):\n","    def __init__(self):\n","        super(SiameseNetwork, self).__init__()\n","        self.fc1 = nn.Linear(768, 128)  \n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 32)\n","        self.fc4 = nn.Linear(32, 1)\n","\n","    def forward_once(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = torch.relu(self.fc3(x))\n","        x = torch.sigmoid(self.fc4(x))\n","        return x\n","\n","    def forward(self, input1, input2):\n","        output1 = self.forward_once(input1)\n","        output2 = self.forward_once(input2)\n","        return output1, output2\n","class SiameseDataset(Dataset):\n","    def __init__(self, data, targets):\n","        self.data = data\n","        self.targets = targets\n","\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx], self.targets[idx]\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["import numpy as np\n","import torch"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchmetrics in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (1.3.2)\n","Requirement already satisfied: numpy>1.20.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from torchmetrics) (1.23.5)\n","Requirement already satisfied: packaging>17.1 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from torchmetrics) (23.1)\n","Requirement already satisfied: torch>=1.10.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from torchmetrics) (2.0.1)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from torchmetrics) (0.11.0)\n","Requirement already satisfied: setuptools in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.8.0)\n","Requirement already satisfied: typing-extensions in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n","Requirement already satisfied: filelock in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.12.4)\n","Requirement already satisfied: sympy in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1)\n","Requirement already satisfied: jinja2 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -rotobuf (c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ywin32 (c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ywin32 (c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages)\n","\n","[notice] A new release of pip is available: 23.1.2 -> 24.0\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentence-transformers in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (2.6.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.32.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sentence-transformers) (4.36.2)\n","Requirement already satisfied: tqdm in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sentence-transformers) (4.66.1)\n","Requirement already satisfied: torch>=1.11.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sentence-transformers) (2.0.1)\n","Requirement already satisfied: numpy in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sentence-transformers) (1.23.5)\n","Requirement already satisfied: scikit-learn in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sentence-transformers) (1.4.1.post1)\n","Requirement already satisfied: scipy in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sentence-transformers) (1.10.1)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sentence-transformers) (0.20.2)\n","Requirement already satisfied: Pillow in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sentence-transformers) (9.5.0)\n","Requirement already satisfied: filelock in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.12.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.12.2)\n","Requirement already satisfied: requests in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n","Requirement already satisfied: packaging>=20.9 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.1)\n","Requirement already satisfied: sympy in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n","Requirement already satisfied: networkx in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n","Requirement already satisfied: jinja2 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: colorama in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.1)\n","Requirement already satisfied: joblib>=1.2.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -rotobuf (c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ywin32 (c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -rotobuf (c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -ywin32 (c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages)\n","\n","[notice] A new release of pip is available: 23.1.2 -> 24.0\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install torchmetrics\n","!pip install sentence-transformers"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["modules.json: 100%|██████████| 229/229 [00:00<00:00, 115kB/s]\n","c:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Gaurav B V\\.cache\\huggingface\\hub\\models--sentence-transformers--bert-base-nli-mean-tokens. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n","config_sentence_transformers.json: 100%|██████████| 122/122 [00:00<00:00, 60.9kB/s]\n","README.md: 100%|██████████| 3.99k/3.99k [00:00<00:00, 1.98MB/s]\n","sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 26.5kB/s]\n","config.json: 100%|██████████| 625/625 [00:00<00:00, 313kB/s]\n","pytorch_model.bin: 100%|██████████| 438M/438M [00:33<00:00, 13.2MB/s] \n","tokenizer_config.json: 100%|██████████| 399/399 [00:00<00:00, 199kB/s]\n","vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.07MB/s]\n","tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 2.28MB/s]\n","added_tokens.json: 100%|██████████| 2.00/2.00 [00:00<00:00, 999B/s]\n","special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 56.0kB/s]\n","1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 95.0kB/s]\n"]},{"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (1x768 and 300x128)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m SiameseNetwork()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Pass the tensors to the model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m output1, output2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput2\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[1;32mIn[6], line 23\u001b[0m, in \u001b[0;36mSiameseNetwork.forward\u001b[1;34m(self, input1, input2)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input1, input2):\n\u001b[1;32m---> 23\u001b[0m     output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_once(input2)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output1, output2\n","Cell \u001b[1;32mIn[6], line 16\u001b[0m, in \u001b[0;36mSiameseNetwork.forward_once\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_once\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n","File \u001b[1;32mc:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[1;32mc:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x768 and 300x128)"]}],"source":["from sentence_transformers import SentenceTransformer\n","\n","# Initialize sentence transformer model\n","sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n","\n","# Suppose we have the following sentences:\n","sentences = ['This is the first sentence.', 'This is the second sentence.']\n","\n","# Generate sentence embeddings\n","embeddings = sbert_model.encode(sentences)\n","\n","# Convert embeddings to tensors\n","input1 = torch.tensor(embeddings[0])\n","input2 = torch.tensor(embeddings[1])\n","\n","# Create an instance of SiameseNetwork\n","model = SiameseNetwork()\n","\n","# Pass the tensors to the model\n","output1, output2 = model(input1, input2)"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T18:40:19.089090Z","iopub.status.busy":"2024-03-21T18:40:19.087621Z","iopub.status.idle":"2024-03-21T18:40:19.098919Z","shell.execute_reply":"2024-03-21T18:40:19.097334Z","shell.execute_reply.started":"2024-03-21T18:40:19.089030Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'input1' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43minput1\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n","\u001b[1;31mNameError\u001b[0m: name 'input1' is not defined"]}],"source":["input1.shape"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T01:51:53.486133Z","iopub.status.busy":"2024-03-22T01:51:53.485516Z","iopub.status.idle":"2024-03-22T01:51:54.673776Z","shell.execute_reply":"2024-03-22T01:51:54.671090Z","shell.execute_reply.started":"2024-03-22T01:51:53.486084Z"},"trusted":true},"outputs":[{"ename":"TypeError","evalue":"linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[43], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      4\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 5\u001b[0m output1, output2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output1, output2, target_scores)\n\u001b[0;32m      7\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[1;32mc:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[1;32mIn[33], line 23\u001b[0m, in \u001b[0;36mSiameseNetwork.forward\u001b[1;34m(self, input1, input2)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input1, input2):\n\u001b[1;32m---> 23\u001b[0m     output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_once(input2)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output1, output2\n","Cell \u001b[1;32mIn[33], line 16\u001b[0m, in \u001b[0;36mSiameseNetwork.forward_once\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_once\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n","File \u001b[1;32mc:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[1;32mc:\\g\\pproject\\aimbot\\bot\\bot\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"]}],"source":["num_epochs = 20\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","    output1, output2 = model(input1, input2)\n","    loss = criterion(output1, output2, target_scores)\n","    loss.backward()\n","    optimizer.step()\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"text/plain":["pandas.core.series.Series"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["type(df['5'])"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n","\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import torch\n","\n","# Assuming df is your DataFrame\n","df = pd.DataFrame({\n","    'col1': [1, 2, 3, 4],\n","    'col2': [5, 6, 7, 8],\n","    'col3': [9, 10, 11, 12]\n","})\n","\n","# Convert DataFrame to numpy array, then to PyTorch Tensor\n","tensor = torch.from_numpy(df.values)\n","\n","# Now you can pass this tensor to your model"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[ 1,  5,  9],\n","        [ 2,  6, 10],\n","        [ 3,  7, 11],\n","        [ 4,  8, 12]])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["tensor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4636988,"sourceId":7896535,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
